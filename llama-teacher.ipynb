{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "llm = Ollama(\n",
    "    model=\"gemma2\"\n",
    ")  # assuming you have Ollama installed and have llama3 model pulled with `ollama pull llama3 `\n",
    "\n",
    "llm.invoke(\"Tell me a joke\")\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.input_schema.schema()\n",
    "chain.invoke({\"context\": \"My parents named me Santiago\", \"question\": \"What's your name'?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "pages = []\n",
    "for i in range(1, 19):\n",
    "    file = f\"books/{i:02d}.txt\"\n",
    "    print(file)\n",
    "    loader = TextLoader(file)\n",
    "    page = loader.load_and_split()\n",
    "    pages.extend(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Importing text splitter from Langchain\n",
    "\n",
    "def split_text(documents):\n",
    "  \"\"\"\n",
    "  Split the text content of the given list of Document objects into smaller chunks.\n",
    "  Args:\n",
    "    documents (list[Document]): List of Document objects containing text content to split.\n",
    "  Returns:\n",
    "    list[Document]: List of Document objects representing the split text chunks.\n",
    "  \"\"\"\n",
    "  # Initialize text splitter with specified parameters\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, # Size of each chunk in characters\n",
    "    chunk_overlap=100, # Overlap between consecutive chunks\n",
    "    length_function=len, # Function to compute the length of the text\n",
    "    add_start_index=True, # Flag to add start index to each chunk\n",
    "  )\n",
    "\n",
    "  # Split documents into smaller chunks using text splitter\n",
    "  chunks = text_splitter.split_documents(documents)\n",
    "  print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "  # Print example of page content and metadata for a chunk\n",
    "  document = chunks[0]\n",
    "  print(document.page_content)\n",
    "  print(document.metadata)\n",
    "\n",
    "  return chunks # Return the list of split text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_text(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks) # Return the length of\n",
    "CHROMA_PATH = \"/Users/nk/Documents/devpunya/AI_Teacher/chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "def save_to_chroma(chunks):\n",
    "  \"\"\"\n",
    "  Save the given list of Document objects to a Chroma database.\n",
    "  Args:\n",
    "  chunks (list[Document]): List of Document objects representing text chunks to save.\n",
    "  Returns:\n",
    "  None\n",
    "  \"\"\"\n",
    "\n",
    "  # Clear out the existing database directory if it exists\n",
    "  if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "  # Create a new Chroma database from the documents using OpenAI embeddings\n",
    "  db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embeddings,\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "\n",
    "  # Persist the database to disk\n",
    "  db.persist()\n",
    "  print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = OllamaEmbeddings(model = \"gemma2\")\n",
    "# vectorstores = DocArrayInMemorySearch.from_documents(pages, embeddings)\n",
    "db = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create retriever\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs= {\"k\": 5}\n",
    ")\n",
    "retriever.invoke(\"Kisari Mohan Ganguli\", tok_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Who is Kisari Mohan Ganguli ?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
